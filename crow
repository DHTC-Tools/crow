#!/usr/bin/env python

import os
import sys
import time
import getopt
import ConfigParser

import pymongo
import htcondor
import classad

try:
	from hashlib import md5
except ImportError:
	# py2.4
	from md5 import md5

DefaultConfig = '''
[crow]
debug = false
brand = generic
historyinterval = 30
queueinterval = 60
detach = true
db = default

[db]
default = mongodb://mongodbserver:27017, crow_%(brand)s

[condor]
historyfile = /var/lib/condor/spool/history
# This adfilter will accept all classads. Use a Matcher expression
# to exclude or include classads by name.
adfilter = /.*/

# matcher-expression := [!]<matcher-atom> [<matcher-expression> logical-conjunction]
# matcher-atom := <regular-expression> | <glob-expression> | <literal-expression>
# regular-expression := /[regular expression tokens]/
# glob-expression := [fnmatch glob, containing ? or *]
# literal-expression := [anything else]
# logical-conjunction := OR | AND | NOT
'''

JobStates = (
	'unexpanded',
	'idle',
	'running',
	'removed',
	'completed',
	'held',
	'submission-error',
	'suspended',
)

class Config(ConfigParser.RawConfigParser):
	def getlist(self, section, option):
		return [x.strip() for x in self.get(section, option).split(',')]


def tfmt(t):
	return '%.3f (%s)' % (float(t), time.ctime(t))


class CrowError(Exception):
	pass

class QueueWatcher(object):
	'''QueueWatcher creates a relationship to a schedd or collector, so
	that it can be queried for running jobs.'''

	def __init__(self, schedd=None, collector=None, hooks={}, interval=30):
		self.hooks = {
			'begin': lambda w, jobs: True,
			'end': lambda w: True,
		}
		self.hooks.update(hooks)
		self._interval = interval

		if schedd:
			if not collector:
				raise TypeError, 'QueueWatcher with schedd requires collector name also'
			def reconnect():
				coll = htcondor.Collector(collector)
				ad = coll.locate(htcondor.DaemonTypes.Schedd, schedd)
				self.source = htcondor.Schedd(ad)

		elif collector:
			def reconnect():
				self.source = htcondor.Collector(collector)

		else:
			def reconnect():
				self.source = htcondor.Schedd()

		self.reconnect = reconnect
		self.reconnect()


	@staticmethod
	def stringify(snapshot):
		'''Ensure that each value in a job snapshot (a dict of
		classad names and values) is a base type:
		int, float, bool, or str.'''
		new = {}
		for k, v in snapshot.items():
			if type(v) in (long, float, bool, str):
				new[k] = v
			else:
				new[k] = str(v)
		return new


	def __iter__(self):
		while True:
			try:
				jobs = self.source.query()
			except Exception, e:
				print >>sys.stderr, 'crow queue %s: %s (reconnecting)' (time.strftime('%Y%m%dT%H%M%S'), str(e))
				self.reconnect()
				continue

			if self.hooks['begin'](self, jobs) is False:
				break
			for job in jobs:
				try:
					job = self.stringify(job)
					yield job
				except Exception, e:
					print >>sys.stderr, str(e)

			if self._interval is None:
				break
			if self.hooks['end'](self) is False:
				break
			time.sleep(self._interval)


class HistoryWatcher(object):
	def __init__(self, file, hooks={}, interval=30):
		self.hooks = {
			'begin': lambda w: True,
			'cycle': lambda w: True,
			'end': lambda w: True,
		}
		self.hooks.update(hooks)
		self._interval = interval
		self._file = file
		self._current = {}
		self._fp = None


	@staticmethod
	def parsevalue(value):
		'''Convert a classad value to a string (without quotes), boolean,
		int, or float as appropriate.'''
		if value.startswith('"'):
			return value.strip('"')

		if value == 'true':
			return True

		if value == 'false':
			return False

		if '.' in value:
			try:
				return float(value)
			except ValueError:
				pass

		try:
			return int(value)
		except ValueError:
			pass

		return value


	def read(self):
		# This lets us catch updates to the current file
		self._fp.seek(self._fp.tell())

		recs = []
		for line in self._fp:
			if line.startswith('***'):
				# end of record
				yield self._current
				self._current = {}
				continue

			ad, value = line.strip().split(' = ', 1)
			self._current[ad] = self.parsevalue(value)


	def __iter__(self):
		# Wait for history file to become available
		while not self._fp:
			try:
				s = os.stat(self._file)
				inode = s.st_ino
				self._fp = open(self._file, 'r')
			except OSError:
				self._fp = None
				if self._interval is None:
					return
				time.sleep(self._interval)

		# history file now exists, and is open

		s = None
		while True:
			# Make sure history file still exists
			try:
				s = os.stat(self._file)
			except OSError:
				# no file (yet?)
				s = None
			if not s and self._interval is not None:
				if self._fp:
					self._fp.close()
					self._fp = None
				if not s:
					time.sleep(self._interval)
					continue

			# Ready to read current file
			if self._fp:
				if self.hooks['begin'](self) is False:
					break
				for snapshot in self.read():
					yield snapshot

			if self._fp and self.hooks['end'](self) is False:
				break

			if self._interval is None:
				self._fp.close()
				break

			sys.stdout.flush()

			# Check whether history file has cycled
			if s and s.st_ino != inode:
				# Old file moved, and new history file available
				if self.hooks['cycle'](self) is False:
					break
				inode = s.st_ino
				self._fp.close()
				self._fp = open(self._file, 'r')
				# no interval delay if file cycles - scan new one immediately

			else:
				time.sleep(self._interval)



class CrowDB(object):
	'''Provides a base algorithm for updating a database with job
	information, abstracted over get/set methods that are implemented
	by a subclass.  See CrowMongo below for example.'''

	class InappropriateDriverError(CrowError): pass

	@classmethod
	def _try(cls, *args):
		#self = cls(*args)
		raise cls.InappropriateDriverError, '%s is a metadriver' % cls.__name__

	@classmethod
	def open(cls, *args):
		symbols = globals()
		for sym, value in symbols.items():
			if type(value) != type(cls):
				continue
			if not issubclass(value, cls):
				continue
			try:
				return value._try(*args)
			except Exception, e:
				pass
		return None

	@staticmethod
	def jobhash(rec):
		'''Compute a unique identifier for an instantaneous job state
		by hashing each classad value (ordered by sorted classad names).
		This will be used to determine whether we already know about this
		exact job state or "version".'''
		m = md5()
		for k in sorted(filter(lambda k: not k.startswith('_'), rec.keys())):
			m.update(str(rec[k]))
		return m.hexdigest()[:16]

	# Given a job description (snapshot), ensure that the job is up to
	# date in the database by updating or inserting records as needed.
	def update(self, job):
		jobid = job['GlobalJobId']
		hash = self.jobhash(job)

		jobent = self.jobent(jobid)
		if jobent:
			# Already present.  Check for significant changes.
			# Latest is a full job snapshot, not a reference.
			latest, lhash = self.latest(jobid, jobent)

			if hash == lhash:
				# No changes whatsoever.
				print '+ no change to %s' % jobid

			# This is odd: condor history gives two 'EnteredCurrentStatus' values.
			# I don't think it's a problem so long as the later one is second in
			# the history file.  (It will overwrite the prior when creating dicts.)
			# If this turns out problematic, we can add logic to choose the better
			# value; in most cases it will be the larger number.

			elif latest['EnteredCurrentStatus'] == job['EnteredCurrentStatus']:
				# No change of state.  Simply update latest.
				print '+ updating %s to latest' % jobid
				self.setlatest(jobid, job, hash)

			else:
				# State change occurred.  Copy latest to history, then save
				# current as latest.
				self.addhistory(jobid, jobent, latest, lhash)
				self.setlatest(jobid, job, hash)

				# Log changes.
				statelog = JobStates[latest['JobStatus']]
				if latest['JobStatus'] != job['LastJobStatus']:
					statelog += ' -> ' + JobStates[job['LastJobStatus']]
				statelog += ' -> ' + JobStates[job['JobStatus']]
				print '+ augmenting history on %s (state %s at %s)' % \
				      (jobid, statelog, tfmt(job['EnteredCurrentStatus']))

		else:
			# No jobent -> never seen before.  Enter ONLY a jobent, no history.
			print '+ adding job %s' % jobid
			self.addjob(jobid, job, hash)


class CrowMongo(CrowDB):
	'''Implements a MongoDB store for job history that follows the
	common update logic in CrowDB above.'''

	@classmethod
	def _try(cls, *args):
		if args[0].startswith('mongodb:'):
			return cls(*args)
		raise cls.InappropriateDriverError, '%s is not a mongodb database spec' % args[0]

	def __init__(self, *args):
		addr = args[0]
		if len(args) > 1:
			dbname = args[1]
		else:
			dbname = 'crow'

		try:
			conn = pymongo.MongoClient(addr)
		except AttributeError:
			conn = pymongo.Connection(addr)
		self.db = conn[dbname]

	# A jobent record has three keys:
	#   _id: the GlobalJobId from condor classads
	#   snapshots: a list of valid snapshot ids
	#   latest: the most recent snapshot stored
	#           (** not necessarily the most recent observed **)
	#   latestid: the snapshot id (hash) of latest

	def jobent(self, jobid):
		return self.db.jobs.find_one({"_id": jobid})

	def latest(self, jobid, jobent):
		return jobent['latest'], jobent['latestid']

	def jobhistory(self, jobid, jobent):
		return jobent['history']

	def setlatest(self, jobid, job, hash):
		self.db.jobs.update({'_id': jobid}, {'$set': {'latest': job}})
		self.db.jobs.update({'_id': jobid}, {'$set': {'latestid': hash}})

	def addhistory(self, jobid, jobent, job, hash):
		hist = self.jobhistory(jobid, jobent) + [hash]

		try:
			job['_id'] = hash
			self.db.snapshots.insert(job)
		except pymongo.errors.DuplicateKeyError:
			pass
		self.db.jobs.update({'_id': jobid}, {'$set': {'history': hist}})

	def addjob(self, jobid, job, hash):
		jobent = {
			'_id': jobid,
			'history': [],
			'latest': job,
			'latestid': hash,
		}
		self.db.jobs.insert(jobent)


class CrowDebug(CrowDB):
	def __init__(self, *args):
		self.pprint = __import__('pprint')

	def update(self, job):
		print job['GlobalJobId'], '(%d classads)' % len(job.keys())
		print self.pprint.pformat(job)


##### Lifted from tanglib
import re
import fnmatch

class Matcher(list):
	OR = 1
	AND = 2
	NOT = 3

	@staticmethod
	def matchfunc(expr):
		negate = False
		negstr = ['!', '']

		if expr.startswith('!'):
			negate = True
			expr = expr[1:].strip()

		if expr.startswith('/') and expr.endswith('/'):
			expr = expr[1:-1]
			rx = re.compile(expr, re.I)
			f = lambda x: negate ^ bool(rx.search(x))
			f.desc = negstr[negate] + 're(' + expr + ')'

		elif '*' in expr or '?' in expr or '[' in expr:
			f = lambda x: negate ^ bool(fnmatch.fnmatch(x, expr))
			f.desc = negstr[negate] + 'fnmatch(' + expr + ')'

		else:
			f = lambda x: negate ^ (x.lower() == expr.lower())
			f.desc = negstr[negate] + 'str(' + expr + ')'

		return f


	def _selector(self, expr):
		expr = expr.strip()
		if expr.lower() == 'or':
			yield self.OR
			return
		if expr.lower() == 'and':
			yield self.AND
			return
		if expr.lower() == 'not':
			yield self.NOT
			return

		yield self.matchfunc(expr)
		return


	def __init__(self, exprs, **kwargs):
		selectors = []
		for expr in exprs:
			for sel in self._selector(expr):
				selectors.append(sel)
		list.__init__(self, selectors)

	def describe(self):
		desc = ''
		for item in self:
			if item == self.OR:
				desc += ' or'
			elif item == self.AND:
				desc += ' and'
			elif item == self.NOT:
				desc += ' not'
			else:
				desc += ' ' + item.desc
		return desc.strip()

	def _run(self, key):
		match = []
		for selector in self:
			if selector == self.AND:
				r = match[-2] and match[-1]
				match = match[:-2] + [r]
			elif selector == self.OR:
				r = match[-2] or match[-1]
				match = match[:-2] + [r]
			elif selector == self.NOT:
				match[-1] = not match[-1]
			else:
				match.append(selector(key))
		return match[-1]

	def __call__(self, args, key=lambda x: x):
		stack = []
		return [arg for arg in args if self._run(key(arg))]

	def __contains__(self, other):
		return self._run(other)
##### End of snitch from tanglib


class preparsed(object):
	def __init__(self, value):
		self.value = value


class JobFilter(list):
	'''A JobFilter is a sequence of JobFilters.'''
	def __call__(self, job):
		for filter in self:
			job = filter(job) or job
		return job


class NullFilter(JobFilter):
	'''A job filter that does nothing to the job; a placeholder.'''
	def __call__(self, job):
		return job


class AdFilter(JobFilter):
	'''A job filter that selects only classads matching a Matcher
	expression.'''

	def __init__(self, rule):
		self.matcher = Matcher(rule.split(' '))

	def __call__(self, job):
		new = {}
		for key in self.matcher(job.keys()):
			new[key] = job[key]
		return new


class EnsureFilter(JobFilter):
	'''A job filter that ensures certain classads are defined.'''

	def __init__(self, ensures):
		self.ensures = ensures

	@classmethod
	def fromconfig(cls, config):
		'''Create an EnsureFilter from a ConfigParser instance.'''
		if not config.has_section('ensure'):
			return NullFilter()
		self = cls({})
		for classad, value in config.items('ensure'):
			self.ensures[classad] = preparsed(self.asbest(value))
		return self

	@staticmethod
	def asquoted(value):
		'''Try to parse as a quoted string.'''
		if value.startswith('"') and value.endswith('"'):
			return value[1:-1]
		if value.startswith("'") and value.endswith("'"):
			return value[1:-1]
		return None

	@staticmethod
	def asint(value):
		'''Try to parse as integer.'''
		try:
			return int(value)
		except:
			return None

	@staticmethod
	def asfloat(value):
		'''Try to parse as floating-point.'''
		try:
			return float(value)
		except:
			return None

	@staticmethod
	def asbool(value):
		'''Try to parse as a boolean word.'''
		value = str(value).lower()
		if value in ('0', 'off', 'no', 'false'):
			return False
		elif value in ('1', 'on', 'yes', 'true'):
			return True
		else:
			return None

	@staticmethod
	def asstr(value):
		'''Parse as a string; does not fail.'''
		return str(value)

	def asbest(self, value):
		'''Pick the best way to parse a value.'''
		return self.asquoted(value) or \
		       self.asint(value) or \
		       self.asfloat(value) or \
		       self.asbool(value) or \
		       self.asstr(value)

	def __call__(self, job):
		'''Apply an ensures set.'''
		keys = [k.lower() for k in job.keys()]
		for key, value in self.ensures.items():
			if key.lower() not in keys:
				# value can be of several types:
				if hasattr(value, '__call__'):
					job[key] = value(job)
				elif value.__class__ == preparsed:
					job[key] = value.value
				else:
					job[key] = self.asbest(value)
		return job


def usage(fp=sys.stderr):
	p = os.path.basename(sys.argv[0])
	s = ' ' * len(p)
	print >>fp, 'usage: %s [-D|--debug] [-C|--configfile file]' % p
	print >>fp, '       %s [-d|--database database-uri] [-b|--brand brand]' % s
	print >>fp, '       %s [--detach] command [args...]' % s
	print >>fp, '       %s [opts] [-i|--interval interval] queue' % p
	print >>fp, '       %s [opts] [-i|--interval interval] history [historyfile ...]' % p
	return 2


def main(args):
	class context(object): pass
	cfg = Config()

	# Create config using defaults above
	import StringIO
	fp = StringIO.StringIO(DefaultConfig)
	cfg.readfp(fp)
	fp.close()

	# Read .ini file from relative to $0
	base = os.path.basename(sys.argv[0])
	home = os.path.dirname(sys.argv[0])
	if os.path.split(home)[-1] == 'bin':
		home = os.path.join(*os.path.split(home)[:-1])

	file = base + '.ini'
	for path in ('/etc', file), (home, 'etc', file), (home, file):
		file = os.path.join(*path)
		#print 'Trying %s ...' % file
		cfg.read(file)

	try:
		opts, args = getopt.getopt(args, 'hDC:d:b:i:', ['help', 'debug', 'config=', 'db=', 'database=', 'databases=', 'brand=', 'interval='])
	except getopt.GetoptError, e:
		print >>sys.stderr, str(e)
		print >>sys.stderr
		return usage()

	for opt, arg in opts:
		if opt in ('-C', '--config'):
			cfg.read(arg)

	databases = []

	brand = cfg.get('crow', 'brand')
	debug = cfg.getboolean('crow', 'debug')
	detach = cfg.getboolean('crow', 'detach')
	_interval = None

	for opt, arg in opts:
		if opt in ('-D', '--debug'):
			debug = True
		if opt in ('-d', '--database', '--databases', '--db'):
			databases.append(arg)
		if opt in ('--detach',):
			detach = True
		if opt in ('-b', '--brand'):
			brand = arg
		if opt in ('-i', '--interval'):
			_interval = int(arg)
		if opt in ('-h', '--help'):
			return usage()

	if not databases:
		databases = cfg.getlist('crow', 'db')
	if not databases:
		databases = ['default']

	if not args:
		return usage()
	cmd = args.pop(0)

	ctx = context()
	def begin(*args):
		ctx.count = 0
		print '** starting scan (%s)' % (tfmt(time.time()))
		sys.stdout.flush()
	def cycle(*args):
		print '** cycled (%s)' % (tfmt(time.time()))
	def end(*args):
		print '-- %d jobs processed (%s)' % (ctx.count, tfmt(time.time()))
		sys.stdout.flush()

	hooks = {
		'begin': begin,
		'cycle': cycle,
		'end': end,
	}

	errs = 0
	dbdefs = {}
	for name, dbargs in cfg.items('db'):
		dbdefs[name] = [arg.strip() % locals() for arg in dbargs.split(',')]
	for name in databases:
		if name not in dbdefs:
			print >>sys.stderr, 'no database named "%s" in configuration' % name
			errs += 1
	if errs:
		return 10
	databases = [(name, CrowDB.open(*dbdefs[name])) for name in databases]

	if debug:
		databases.insert(0, ('debug', CrowDebug()))

	def updateall(snapshot):
		for name, db in databases:
			print name, db
			db.update(snapshot)

	jobfilter = JobFilter()
	if cfg.has_section('ensure'):
		jobfilter.append(EnsureFilter.fromconfig(cfg))

	if cfg.has_option('condor', 'adfilter'):
		jobfilter.append(AdFilter(cfg.get('condor', 'adfilter') + ' GlobalJobId or'))

	def queue(args):
		interval = _interval or cfg.getint('crow', 'queueinterval')
		w = QueueWatcher(interval=interval, hooks=hooks)
		for snapshot in w:
			snapshot = jobfilter(snapshot)
			ctx.count += 1
			updateall(snapshot)
		return 0

	def history(args):
		interval = _interval or cfg.getint('crow', 'historyinterval')
		if args:
			for arg in args:
				# Given args, do a one-time pass over each named file
				w = HistoryWatcher(arg, interval=None, hooks=hooks)
				for snapshot in w:
					snapshot = jobfilter(snapshot)
					ctx.count += 1
					updateall(snapshot)
		else:
			file = cfg.get('condor', 'historyfile')
			w = HistoryWatcher(file, interval=interval, hooks=hooks)
			for snapshot in w:
				snapshot = jobfilter(snapshot)
				ctx.count += 1
				updateall(snapshot)
		return 0

	if cmd == 'printconf':
		cfg.write(sys.stdout)
	elif cmd == 'queue':
		queue(args)
	elif cmd == 'history':
		history(args)
	elif cmd == 'all':
		# this will be recommended, but not yet -
		# we need better logging control first. Also better
		# KeyboardInterrupt handling.
		pid1 = os.fork()
		if pid1 == 0:
			return queue(args)
		pid2 = os.fork()
		if pid2 == 0:
			return history(args)
		if not detach:
			os.waitpid(pid1)
			os.waitpid(pid2)
			return 0
	else:
		print >>sys.stderr, 'unknown command:', cmd
		return usage()

if __name__ == '__main__':
	sys.exit(main(sys.argv[1:]))
